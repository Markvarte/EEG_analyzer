{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Markvarte/EEG_analyzer/blob/master/eeg_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0XGaa-ejHXtc"
   },
   "outputs": [],
   "source": [
    "# path: /content/EEG_A.edf -> https://zenodo.org/records/160118\n",
    "# sleep-edf database -> https://www.physionet.org/content/sleep-edfx/1.0.0/sleep-telemetry/#files-panel\n",
    "# child-edf database -> https://physionet.org/content/chbmit/1.0.0/chb01/#files-panel\n",
    "# https://hypnodynecorp.com/downloads.php ? some kind of edf DB too?\n",
    "# additional: pip install mne, braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "co8Ms9Y7TPla"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'span'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbraindecode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGNetv4 \u001b[38;5;28;01mas\u001b[39;00m EEGNet\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/braindecode/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EEGRegressor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/braindecode/classifier.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNet\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EpochScoring\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetClassifier\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/skorch/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m History\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNet\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetClassifier\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetBinaryClassifier\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetRegressor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/skorch/classifier.py:55\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNeuralNetClassifier\u001b[39;00m(NeuralNet, ClassifierMixin):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m get_neural_net_clf_doc(NeuralNet\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m             module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     66\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/skorch/classifier.py:56\u001b[0m, in \u001b[0;36mNeuralNetClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNeuralNetClassifier\u001b[39;00m(NeuralNet, ClassifierMixin):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m get_neural_net_clf_doc(NeuralNet\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m             module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     66\u001b[0m     ):\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28msuper\u001b[39m(NeuralNetClassifier, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     68\u001b[0m             module,\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     73\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/skorch/classifier.py:48\u001b[0m, in \u001b[0;36mget_neural_net_clf_doc\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     46\u001b[0m doc \u001b[38;5;241m=\u001b[39m neural_net_clf_doc_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m doc\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     47\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+)(criterion .*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn)(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms.+)\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,99}\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m start, end \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39msearch(doc)\u001b[38;5;241m.\u001b[39mspan()\n\u001b[1;32m     49\u001b[0m doc \u001b[38;5;241m=\u001b[39m doc[:start] \u001b[38;5;241m+\u001b[39m neural_net_clf_additional_text \u001b[38;5;241m+\u001b[39m doc[end:]\n\u001b[1;32m     50\u001b[0m doc \u001b[38;5;241m=\u001b[39m doc \u001b[38;5;241m+\u001b[39m neural_net_clf_additional_attribute\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'span'"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from braindecode.models import EEGNetv4 as EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y5Q-ZByWL4a"
   },
   "outputs": [],
   "source": [
    "# window_size: зависит от частоты дискретизации\n",
    "# частота записи ЕЕГ в 512 герц -> окно в 1 секунду\n",
    "# частота записи ЕЕГ в 256 герц -> окно в 2 секунды\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, file_list, window_size=512, cut_step=256):\n",
    "        self.samples = []\n",
    "        for f in file_list:\n",
    "            raw = mne.io.read_raw_edf(f, preload=True)\n",
    "            data = raw.get_data()  # [channels, time]\n",
    "\n",
    "            # TODO: фильтрация очищение от шума и т.д.\n",
    "            \n",
    "            # режем на куски фиксированного размера\n",
    "            # возможны несколько стратегий- без overlap, c overlap, c padding.\n",
    "            # тут с overlap- шаг 256, окно 512\n",
    "            # пример- [0:512], [256:512+256(768)], [512:768+256(1024)], ...\n",
    "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
    "                segment = data[:, start:start+window_size]\n",
    "                self.samples.append(segment.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.samples[idx]\n",
    "        # SimCLR-style аугментации\n",
    "        # проверить правильность !\n",
    "        def augment(sig):\n",
    "            sig = sig + 0.01*np.random.randn(*sig.shape)       # шум\n",
    "            sig = np.roll(sig, np.random.randint(-10, 10), -1) # сдвиг\n",
    "            return sig\n",
    "        return augment(x), augment(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Uuvu0tn_Y2JA"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====== Contrastive Loss ======\n",
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    similarity_matrix = torch.matmul(representations, representations.T)\n",
    "    labels = torch.arange(z1.size(0)).repeat(2)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "    labels = labels[~mask].view(labels.shape[0], -1)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "    negatives = similarity_matrix[~labels.bool()].view(labels.shape[0], -1)\n",
    "    logits = torch.cat([positives, negatives], dim=1)\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(z1.device)\n",
    "    logits = logits / temperature\n",
    "    return F.cross_entropy(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Backbone (EEGNet) ======\n",
    "backbone = EEGNet(\n",
    "    n_chans=21,                 # число каналов\n",
    "    n_outputs=128,              # эмбеддинги\n",
    "    input_window_samples=512,\n",
    "    final_conv_length='auto'\n",
    ")\n",
    "\n",
    "# убираем head → используем только фичи\n",
    "backbone.classify = False\n",
    "backbone = backbone.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(backbone.parameters(), lr=1e-3)\n",
    "\n",
    "# ====== Обучение ======\n",
    "dataset = EEGDataset([\"file1.edf\", \"file2.edf\", ...])\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x1, x2 in loader:\n",
    "        x1, x2 = x1.cuda(), x2.cuda()\n",
    "        z1 = backbone(x1)  # эмбеддинги\n",
    "        z2 = backbone(x2)\n",
    "        loss = contrastive_loss(z1, z2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch} | Loss {loss.item():.4f}\")\n",
    "\n",
    "torch.save(backbone.state_dict(), \"backbone_ssl.pt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmPxKXziuCWN/xAR0ueA7C",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

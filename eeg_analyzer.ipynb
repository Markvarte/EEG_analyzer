{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmPxKXziuCWN/xAR0ueA7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markvarte/EEG_analyzer/blob/master/eeg_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0XGaa-ejHXtc"
      },
      "outputs": [],
      "source": [
        "# path: /content/EEG_A.edf -> https://zenodo.org/records/160118\n",
        "# additional: pip install mne, braindecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from braindecode.models import EEGNetv4 as EEGNet"
      ],
      "metadata": {
        "id": "co8Ms9Y7TPla"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# window_size: зависит от частоты дискретизации\n",
        "# частота записи ЕЕГ в 512 герц -> окно в 1 секунду\n",
        "# частота записи ЕЕГ в 256 герц -> окно в 2 секунды\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, file_list, window_size=512, cut_step=256):\n",
        "        self.samples = []\n",
        "        for f in file_list:\n",
        "            raw = mne.io.read_raw_edf(f, preload=True)\n",
        "            data = raw.get_data()  # [channels, time]\n",
        "            # режем на куски фиксированного размера\n",
        "            # возможны несколько стратегий- без overlap, c overlap, c padding.\n",
        "            # тут с overlap- шаг 256, окно 512\n",
        "            # пример- [0:512], [256:512+256(768)], [512:768+256(1024)], ...\n",
        "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
        "                segment = data[:, start:start+window_size]\n",
        "                self.samples.append(segment.astype(np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.samples[idx]\n",
        "        # SimCLR-style аугментации\n",
        "        def augment(sig):\n",
        "            sig = sig + 0.01*np.random.randn(*sig.shape)       # шум\n",
        "            sig = np.roll(sig, np.random.randint(-10, 10), -1) # сдвиг\n",
        "            return sig\n",
        "        return augment(x), augment(x)"
      ],
      "metadata": {
        "id": "6Y5Q-ZByWL4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Contrastive Loss ======\n",
        "def contrastive_loss(z1, z2, temperature=0.5):\n",
        "    z1 = F.normalize(z1, dim=1)\n",
        "    z2 = F.normalize(z2, dim=1)\n",
        "    representations = torch.cat([z1, z2], dim=0)\n",
        "    similarity_matrix = torch.matmul(representations, representations.T)\n",
        "    labels = torch.arange(z1.size(0)).repeat(2)\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "    mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
        "    labels = labels[~mask].view(labels.shape[0], -1)\n",
        "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "    negatives = similarity_matrix[~labels.bool()].view(labels.shape[0], -1)\n",
        "    logits = torch.cat([positives, negatives], dim=1)\n",
        "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(z1.device)\n",
        "    logits = logits / temperature\n",
        "    return F.cross_entropy(logits, labels)\n",
        "\n",
        "# ====== Backbone (EEGNet) ======\n",
        "backbone = EEGNet(\n",
        "    n_chans=21,                 # число каналов\n",
        "    n_outputs=128,              # эмбеддинги\n",
        "    input_window_samples=512,\n",
        "    final_conv_length='auto'\n",
        ")\n",
        "\n",
        "# убираем head → используем только фичи\n",
        "backbone.classify = False\n",
        "backbone = backbone.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(backbone.parameters(), lr=1e-3)\n",
        "\n",
        "# ====== Обучение ======\n",
        "dataset = EEGDataset([\"file1.edf\", \"file2.edf\", ...])\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for x1, x2 in loader:\n",
        "        x1, x2 = x1.cuda(), x2.cuda()\n",
        "        z1 = backbone(x1)  # эмбеддинги\n",
        "        z2 = backbone(x2)\n",
        "        loss = contrastive_loss(z1, z2)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch} | Loss {loss.item():.4f}\")\n",
        "\n",
        "torch.save(backbone.state_dict(), \"backbone_ssl.pt\")\n"
      ],
      "metadata": {
        "id": "Uuvu0tn_Y2JA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
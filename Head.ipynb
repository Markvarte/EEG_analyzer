{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e23c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level('ERROR')  # выводить только ошибки\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from braindecode.models import EEGNetv4 as EEGNet\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8be00",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd40252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(raw):\n",
    "    \n",
    "    raw_resampled = raw.copy().resample(256)\n",
    "    \n",
    "    # Убираем дрейф и ВЧ-шум → 0.5–45 Гц, мышечные артефакты (EMG), движение кожи\n",
    "    raw_filtered = raw_resampled.copy().filter(l_freq=0.5, h_freq=45)\n",
    "    \n",
    "    # Удаление сетевой наводки (50 Гц)\n",
    "    raw_filtered.notch_filter(freqs=[50])\n",
    "    \n",
    "    # Референцированиe\n",
    "    # Пересчёт в среднее по всем каналам\n",
    "    raw_filtered.set_eeg_reference('average')\n",
    "    # дополнительно можно ICA -> find_bads_eog\n",
    "    \n",
    "    # Нормализация\n",
    "    data = raw_filtered.get_data()  # [n_channels, n_times]\n",
    "    # Z-score по каналам -убрать индивидуальные различия каналов по масштабу, сделать данные сопоставимыми\n",
    "    data_zscored = (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n",
    "    return data_zscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c80d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datasets with differences in channels\n",
    "# globally used in 2 classes :(\n",
    "needed_channels = [\n",
    "     'C3-P3',\n",
    "     'C4-P4',\n",
    "     'CZ-PZ',\n",
    "     'F3-C3',\n",
    "     'F4-C4',\n",
    "     'F7-T7',\n",
    "     'F8-T8',\n",
    "     'FP1-F3',\n",
    "     'FP1-F7',\n",
    "     'FP2-F4',\n",
    "     'FP2-F8',\n",
    "     'FT10-T8',\n",
    "     'FT9-FT10',\n",
    "     'FZ-CZ',\n",
    "     'P3-O1',\n",
    "     'P4-O2',\n",
    "     'P7-O1',\n",
    "     'P7-T7',\n",
    "     'P8-O2',\n",
    "     'T7-FT9',\n",
    "     'T7-P7',\n",
    "     'T8-P8-0']\n",
    "def get_valid_files(dataset):\n",
    "\n",
    "    res_set = []\n",
    "\n",
    "    for f, label in dataset:\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(f, preload=False, verbose=False)\n",
    "            channels = raw.ch_names\n",
    "            if all(ch in channels for ch in needed_channels):\n",
    "                res_set.append((f, label))\n",
    "        except Exception as e:\n",
    "            print(f\"{f.name}: {e}\")\n",
    "            \n",
    "    return res_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf70232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161\n",
      "454\n",
      "258\n",
      "2131 342 253\n"
     ]
    }
   ],
   "source": [
    "# Get list of files and labels\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import mne\n",
    "from pathlib import Path\n",
    "training_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_set.extend(training_seiz)\n",
    "print(len(training_set))\n",
    "\n",
    "\n",
    "val_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_set.extend(val_seiz)\n",
    "print(len(val_set))\n",
    "\n",
    "\n",
    "test_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_set.extend(test_seiz)\n",
    "print(len(test_set))\n",
    "\n",
    "\n",
    "res_training_set = get_valid_files(training_set)\n",
    "res_val_set = get_valid_files(val_set)\n",
    "res_test_set = get_valid_files(test_set)\n",
    "\n",
    "print(len(res_training_set), len(res_val_set), len(res_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a2a0a",
   "metadata": {},
   "source": [
    "#### HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15f4422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<decorator-gen-472>:4: FutureWarning: NOTE: EEGNetv4() is a deprecated class. `EEGNetv4` was renamed to `EEGNet` in v1.12; this alias will be removed in v1.14..\n"
     ]
    }
   ],
   "source": [
    "backbone = EEGNet(\n",
    "    n_chans=22, \n",
    "    n_outputs=128, \n",
    "    n_times=512,\n",
    "    final_conv_length='auto'\n",
    ")\n",
    "backbone.classify = False\n",
    "\n",
    "# Загружаем чекпойнт с CPU, чтобы избежать CUDA assert\n",
    "checkpoint = torch.load(\"backbone_ssl_epoch04.pt\", map_location=\"cpu\")\n",
    "\n",
    "# Извлекаем именно веса модели\n",
    "state_dict = checkpoint['model_state']\n",
    "\n",
    "# zагружаем в модель\n",
    "backbone.load_state_dict(state_dict)\n",
    "\n",
    "# переносим на GPU\n",
    "backbone = backbone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3565e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head\n",
    "# Head class for classification/regression\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=2):  # out_dim=2 -> 2 pattern first\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "head = Head(in_dim=128, out_dim=2).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(backbone.parameters())+list(head.parameters()), lr=1e-4)\n",
    "# Для создания нескольких независимых друг от друга паттернов (мульти-лейбл) нужен .Sigmoid()\n",
    "# функция ниже как то применяет этот сигмоид у себя внутри\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with labels\n",
    "class EEGPatternDataset(Dataset):\n",
    "    def __init__(self, file_label_pairs, window_size=512, cut_step=256):\n",
    "        self.samples, self.labels = [], []\n",
    "        for f, y in file_label_pairs:\n",
    "            raw = mne.io.read_raw_edf(f, preload=True)\n",
    "            # select only chanells above (for datasets with different channels)\n",
    "            raw.pick(needed_channels)\n",
    "            # filter raw record, return some numpy obj\n",
    "            data = get_filtered_data(raw)\n",
    "            # превращает обычный список в торч тензор\n",
    "            # y = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
    "                segment = data[:, start:start+window_size]\n",
    "                \n",
    "                self.samples.append(segment.astype(np.float32))\n",
    "                # гарантируем, что y — float32 tensor\n",
    "                label_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "                self.labels.append(label_tensor)  # метка паттерна\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.samples[idx], dtype=torch.float32)\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head(backbone, head, train_loader, val_loader, epochs=10, lr=1e-3, fine_tune=False):\n",
    "    \n",
    "    \n",
    "    # saving histories\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Заморозить backbone\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(head.parameters(), lr=lr)\n",
    "    # nn.BCELoss()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        head.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            # y.float().unsqueeze(1).cuda()\n",
    "            x, y = x.cuda(), y.float().cuda()\n",
    "            with torch.no_grad():\n",
    "                z = backbone(x)\n",
    "            preds = head(z)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Train loss: {total_loss / len(train_loader):.4f}\")\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Валидация\n",
    "        \n",
    "        # Предсказания и метки собираем по всей валидации\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        head.eval()\n",
    "        correct, total, val_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                # метрики для анализа F1\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "                # correct += ((preds > 0.5).float() == y).sum().item()\n",
    "                correct += ((torch.sigmoid(preds) > 0.5).float() == y).sum().item()\n",
    "                total += y.size(0)\n",
    "                \n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_acc = correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} |\"\n",
    "              f\" Train loss: {avg_train_loss:.4f} | Val loss: {avg_val_loss:.4f} | Val acc: {val_acc:.3f}\")\n",
    "        \n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "        # Бинаризация (0.5 порог)\n",
    "        binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "        precision = precision_score(all_labels, binary_preds, average='macro')\n",
    "        recall = recall_score(all_labels, binary_preds, average='macro')\n",
    "        f1 = f1_score(all_labels, binary_preds, average='macro')\n",
    "\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "        \n",
    "    # ==== 4. Fine-tuning ====\n",
    "    if fine_tune:\n",
    "        print(\"\\nРазмораживаем верхние слои backbone для тонкой настройки...\")\n",
    "        for p in list(backbone.parameters())[-6:]: # total = 12 (4-6 to unfreeze is ok)\n",
    "            p.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(list(backbone.parameters())[-6:] + list(head.parameters()), lr=1e-4)\n",
    "\n",
    "        for epoch in range(3):  # несколько эпох fine-tuning\n",
    "            head.train()\n",
    "            for x, y in tqdm(train_loader, desc=f\"Fine-tune epoch {epoch+1}\"):\n",
    "                # y.float().unsqueeze(1).cuda()\n",
    "                x, y = x.cuda(), y.float().cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                loss = criterion(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f\"Fine-tune epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        print(\"Fine-tuning завершён!\")\n",
    "        \n",
    "\n",
    "    # Сохранение весов \n",
    "    torch.save(head.state_dict(), \"head.pt\")\n",
    "    torch.save(backbone.state_dict(), \"backbone_finetuned.pt\")\n",
    "\n",
    "    # Сохранение истории метрик \n",
    "    history = pd.DataFrame({\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies\n",
    "    })\n",
    "    history.to_csv(\"training_history_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b6d0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 5) how to use: after fine-tune validate head -> may need if-else block in code above\n",
    "# 3) Load backbone for 4 epoch (as the best per val-loss) -> >:( something broke >:(\n",
    "# 4) F1, recall, precision -> +, можно ещё ROC-AUC / PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88eb676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging to show right trace to find an error -> синхронный запуск, не включать при норм работе!\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab876964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████████████████| 1567/1567 [00:01<00:00, 930.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5035\n",
      "Epoch 1/10 | Train loss: 0.5035 | Val loss: 0.8370 | Val acc: 1.000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# head initialized earlier\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# backbone initialized earlier\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfine_tune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 73\u001b[0m, in \u001b[0;36mtrain_head\u001b[0;34m(backbone, head, train_loader, val_loader, epochs, lr, fine_tune)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Бинаризация (0.5 порог)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m binary_preds \u001b[38;5;241m=\u001b[39m (all_preds \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, binary_preds)\n\u001b[1;32m     75\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(all_labels, binary_preds)\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2524\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2357\u001b[0m     {\n\u001b[1;32m   2358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2384\u001b[0m ):\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   2386\u001b[0m \n\u001b[1;32m   2387\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2524\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1996\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \n\u001b[1;32m   1829\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1996\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1779\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1778\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1779\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1780\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1781\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1782\u001b[0m         )\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1784\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1790\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples']."
     ]
    }
   ],
   "source": [
    "# res_training_set initialized earlier\n",
    "# res_val_set initialized earlier\n",
    "train_ds = EEGPatternDataset(res_training_set)\n",
    "val_ds = EEGPatternDataset(res_val_set)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "# head initialized earlier\n",
    "# backbone initialized earlier\n",
    "\n",
    "train_head(backbone, head, train_loader, val_loader, epochs=10, fine_tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e3237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG)",
   "language": "python",
   "name": "eeg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

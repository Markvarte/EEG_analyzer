{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e23c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level('ERROR')  # выводить только ошибки\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from braindecode.models import EEGNetv4 as EEGNet\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8be00",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd40252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(raw):\n",
    "    \n",
    "    raw_resampled = raw.copy().resample(256)\n",
    "    \n",
    "    # Убираем дрейф и ВЧ-шум → 0.5–45 Гц, мышечные артефакты (EMG), движение кожи\n",
    "    raw_filtered = raw_resampled.copy().filter(l_freq=0.5, h_freq=45)\n",
    "    \n",
    "    # Удаление сетевой наводки (50 Гц)\n",
    "    raw_filtered.notch_filter(freqs=[50])\n",
    "    \n",
    "    # Референцированиe\n",
    "    # Пересчёт в среднее по всем каналам\n",
    "    raw_filtered.set_eeg_reference('average')\n",
    "    # дополнительно можно ICA -> find_bads_eog\n",
    "    \n",
    "    # Нормализация\n",
    "    data = raw_filtered.get_data()  # [n_channels, n_times]\n",
    "    # Z-score по каналам -убрать индивидуальные различия каналов по масштабу, сделать данные сопоставимыми\n",
    "    data_zscored = (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n",
    "    return data_zscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c80d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datasets with differences in channels\n",
    "# globally used in 2 classes :(\n",
    "needed_channels = [\n",
    "     'C3-P3',\n",
    "     'C4-P4',\n",
    "     'CZ-PZ',\n",
    "     'F3-C3',\n",
    "     'F4-C4',\n",
    "     'F7-T7',\n",
    "     'F8-T8',\n",
    "     'FP1-F3',\n",
    "     'FP1-F7',\n",
    "     'FP2-F4',\n",
    "     'FP2-F8',\n",
    "     'FT10-T8',\n",
    "     'FT9-FT10',\n",
    "     'FZ-CZ',\n",
    "     'P3-O1',\n",
    "     'P4-O2',\n",
    "     'P7-O1',\n",
    "     'P7-T7',\n",
    "     'P8-O2',\n",
    "     'T7-FT9',\n",
    "     'T7-P7',\n",
    "     'T8-P8-0']\n",
    "def get_valid_files(dataset):\n",
    "\n",
    "    res_set = []\n",
    "\n",
    "    for f, label in dataset:\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(f, preload=False, verbose=False)\n",
    "            channels = raw.ch_names\n",
    "            if all(ch in channels for ch in needed_channels):\n",
    "                res_set.append((f, label))\n",
    "        except Exception as e:\n",
    "            print(f\"{f.name}: {e}\")\n",
    "            \n",
    "    return res_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf70232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161\n",
      "454\n",
      "258\n",
      "2131 342 253\n"
     ]
    }
   ],
   "source": [
    "# Get list of files and labels\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import mne\n",
    "from pathlib import Path\n",
    "training_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_set.extend(training_seiz)\n",
    "print(len(training_set))\n",
    "\n",
    "\n",
    "val_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_set.extend(val_seiz)\n",
    "print(len(val_set))\n",
    "\n",
    "\n",
    "test_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_set.extend(test_seiz)\n",
    "print(len(test_set))\n",
    "\n",
    "\n",
    "res_training_set = get_valid_files(training_set)\n",
    "res_val_set = get_valid_files(val_set)\n",
    "res_test_set = get_valid_files(test_set)\n",
    "\n",
    "print(len(res_training_set), len(res_val_set), len(res_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a2a0a",
   "metadata": {},
   "source": [
    "#### HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with labels\n",
    "class EEGPatternDataset(Dataset):\n",
    "    def __init__(self, file_label_pairs, window_size=512, cut_step=256):\n",
    "        self.samples, self.labels = [], []\n",
    "        for f, y in file_label_pairs:\n",
    "            raw = mne.io.read_raw_edf(f, preload=True)\n",
    "            # select only chanells above (for datasets with different channels)\n",
    "            raw.pick(needed_channels)\n",
    "            # filter raw record, return some numpy obj\n",
    "            data = get_filtered_data(raw)\n",
    "            # превращает обычный список в торч тензор\n",
    "            # y = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
    "                segment = data[:, start:start+window_size]\n",
    "                \n",
    "                self.samples.append(segment.astype(np.float32))\n",
    "                # гарантируем, что y — float32 tensor\n",
    "                label_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "                self.labels.append(label_tensor)  # метка паттерна\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.samples[idx], dtype=torch.float32)\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head(backbone, head, train_loader, val_loader, epochs=10, lr=1e-3, fine_tune=False):\n",
    "    \n",
    "    \n",
    "    # saving histories\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    ROC_AUCs = []\n",
    "    PR_AUCs = []\n",
    "    \n",
    "    # Заморозить backbone\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(head.parameters(), lr=lr)\n",
    "    # Для создания нескольких независимых друг от друга паттернов (мульти-лейбл) нужен .Sigmoid()\n",
    "    # функция ниже как то применяет этот сигмоид у себя внутри\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        head.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            # y.float().unsqueeze(1).cuda()\n",
    "            x, y = x.cuda(), y.float().cuda()\n",
    "            with torch.no_grad():\n",
    "                z = backbone(x)\n",
    "            preds = head(z)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Train loss: {total_loss / len(train_loader):.4f}\")\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Валидация\n",
    "        \n",
    "        # Предсказания и метки собираем по всей валидации\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        head.eval()\n",
    "        correct, total, val_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                # метрики для анализа F1\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "                # correct += ((preds > 0.5).float() == y).sum().item()\n",
    "                correct += ((torch.sigmoid(preds) > 0.5).float() == y).sum().item()\n",
    "                total += y.size(0)\n",
    "                \n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_acc = correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} |\"\n",
    "              f\" Train loss: {avg_train_loss:.4f} | Val loss: {avg_val_loss:.4f} | Val acc: {val_acc:.3f}\")\n",
    "        \n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "        # Бинаризация (0.5 порог)\n",
    "        binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "        precision = precision_score(all_labels, binary_preds, average='macro')\n",
    "        precisions.append(precision)\n",
    "        recall = recall_score(all_labels, binary_preds, average='macro')\n",
    "        recalls.append(recall)\n",
    "        f1 = f1_score(all_labels, binary_preds, average='macro')\n",
    "        F1s.append(f1)\n",
    "        auc_macro = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "        ROC_AUCs.append(auc_macro)\n",
    "        pr_auc = average_precision_score(all_labels, all_preds, average='macro')\n",
    "        PR_AUCs.append(pr_auc)\n",
    "\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, ROC-AUC: {auc_macro:.3f}, PR-AUC: {pr_auc:.3f}\")\n",
    "        \n",
    "\n",
    "        \n",
    "    # ==== 4. Fine-tuning ====\n",
    "    if fine_tune:\n",
    "        print(\"\\nРазмораживаем верхние слои backbone для тонкой настройки...\")\n",
    "        for p in list(backbone.parameters())[-6:]: # total = 12 (4-6 to unfreeze is ok)\n",
    "            p.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(list(backbone.parameters())[-6:] + list(head.parameters()), lr=1e-4)\n",
    "\n",
    "        for epoch in range(3):  # несколько эпох fine-tuning\n",
    "            head.train()\n",
    "            for x, y in tqdm(train_loader, desc=f\"Fine-tune epoch {epoch+1}\"):\n",
    "                # y.float().unsqueeze(1).cuda()\n",
    "                x, y = x.cuda(), y.float().cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                loss = criterion(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f\"Fine-tune epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        print(\"Fine-tuning завершён!\")\n",
    "        \n",
    "\n",
    "    # Сохранение весов \n",
    "    torch.save(head.state_dict(), \"head.pt\")\n",
    "    torch.save(backbone.state_dict(), \"backbone_finetuned.pt\")\n",
    "\n",
    "    # Сохранение истории метрик \n",
    "    history = pd.DataFrame({\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies,\n",
    "        \"precision\": precisions,\n",
    "        \"recall\": recalls,\n",
    "        \"F1\": F1s,\n",
    "        \"ROC-AUC\": ROC_AUCs,\n",
    "        \"PR-AUC\": PR_AUCs\n",
    "    })\n",
    "    history.to_csv(\"training_history_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b6d0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 3) Load backbone for 4 epoch (as the best per val-loss) -> >:( something broke >:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88eb676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging to show right trace to find an error -> синхронный запуск, не включать при норм работе!\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15f4422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<decorator-gen-472>:4: FutureWarning: NOTE: EEGNetv4() is a deprecated class. `EEGNetv4` was renamed to `EEGNet` in v1.12; this alias will be removed in v1.14..\n"
     ]
    }
   ],
   "source": [
    "backbone = EEGNet(\n",
    "    n_chans=22, \n",
    "    n_outputs=128, \n",
    "    n_times=512,\n",
    "    final_conv_length='auto'\n",
    ")\n",
    "backbone.classify = False\n",
    "\n",
    "# Загружаем чекпойнт с CPU, чтобы избежать CUDA assert\n",
    "checkpoint = torch.load(\"backbone_ssl_epoch04.pt\", map_location=\"cpu\")\n",
    "\n",
    "# Извлекаем именно веса модели\n",
    "state_dict = checkpoint['model_state']\n",
    "\n",
    "# zагружаем в модель\n",
    "backbone.load_state_dict(state_dict)\n",
    "\n",
    "# переносим на GPU\n",
    "backbone = backbone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3565e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head\n",
    "# Head class for classification/regression\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=2):  # out_dim=2 -> 2 pattern first\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "head = Head(in_dim=128, out_dim=2).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(backbone.parameters())+list(head.parameters()), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab876964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1052.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4588\n",
      "Epoch 1/10 | Train loss: 0.4588 | Val loss: 0.7863 | Val acc: 1.105\n",
      "Precision: 0.621, Recall: 0.419, F1: 0.407, ROC-AUC: 0.668, PR-AUC: 0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1075.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4567\n",
      "Epoch 2/10 | Train loss: 0.4567 | Val loss: 0.8143 | Val acc: 1.100\n",
      "Precision: 0.615, Recall: 0.418, F1: 0.390, ROC-AUC: 0.669, PR-AUC: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1074.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4580\n",
      "Epoch 3/10 | Train loss: 0.4580 | Val loss: 0.7680 | Val acc: 1.121\n",
      "Precision: 0.653, Recall: 0.398, F1: 0.402, ROC-AUC: 0.669, PR-AUC: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1071.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4540\n",
      "Epoch 4/10 | Train loss: 0.4540 | Val loss: 0.8127 | Val acc: 1.107\n",
      "Precision: 0.640, Recall: 0.424, F1: 0.389, ROC-AUC: 0.677, PR-AUC: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1051.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4543\n",
      "Epoch 5/10 | Train loss: 0.4543 | Val loss: 0.7522 | Val acc: 1.148\n",
      "Precision: 0.641, Recall: 0.397, F1: 0.423, ROC-AUC: 0.664, PR-AUC: 0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1106.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4536\n",
      "Epoch 6/10 | Train loss: 0.4536 | Val loss: 0.8281 | Val acc: 1.105\n",
      "Precision: 0.621, Recall: 0.435, F1: 0.410, ROC-AUC: 0.675, PR-AUC: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1079.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4545\n",
      "Epoch 7/10 | Train loss: 0.4545 | Val loss: 0.7897 | Val acc: 1.136\n",
      "Precision: 0.630, Recall: 0.420, F1: 0.415, ROC-AUC: 0.675, PR-AUC: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1051.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4524\n",
      "Epoch 8/10 | Train loss: 0.4524 | Val loss: 0.8359 | Val acc: 1.099\n",
      "Precision: 0.652, Recall: 0.438, F1: 0.376, ROC-AUC: 0.693, PR-AUC: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████| 1567/1567 [00:01<00:00, 1100.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4547\n",
      "Epoch 9/10 | Train loss: 0.4547 | Val loss: 0.7632 | Val acc: 1.142\n",
      "Precision: 0.629, Recall: 0.414, F1: 0.413, ROC-AUC: 0.678, PR-AUC: 0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████| 1567/1567 [00:01<00:00, 1109.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4531\n",
      "Epoch 10/10 | Train loss: 0.4531 | Val loss: 0.7549 | Val acc: 1.149\n",
      "Precision: 0.640, Recall: 0.414, F1: 0.426, ROC-AUC: 0.674, PR-AUC: 0.656\n"
     ]
    }
   ],
   "source": [
    "# res_training_set initialized earlier\n",
    "# res_val_set initialized earlier\n",
    "train_ds = EEGPatternDataset(res_training_set)\n",
    "val_ds = EEGPatternDataset(res_val_set)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "# head initialized earlier\n",
    "# backbone initialized earlier\n",
    "\n",
    "train_head(backbone, head, train_loader, val_loader, epochs=10, fine_tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG)",
   "language": "python",
   "name": "eeg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

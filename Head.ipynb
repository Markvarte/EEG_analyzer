{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e23c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level('ERROR')  # выводить только ошибки\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from braindecode.models import EEGNetv4 as EEGNet\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8be00",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bd40252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(raw):\n",
    "    \n",
    "    raw_resampled = raw.copy().resample(256)\n",
    "    \n",
    "    # Убираем дрейф и ВЧ-шум → 0.5–45 Гц, мышечные артефакты (EMG), движение кожи\n",
    "    raw_filtered = raw_resampled.copy().filter(l_freq=0.5, h_freq=45)\n",
    "    \n",
    "    # Удаление сетевой наводки (50 Гц)\n",
    "    raw_filtered.notch_filter(freqs=[50])\n",
    "    \n",
    "    # Референцированиe\n",
    "    # Пересчёт в среднее по всем каналам\n",
    "    raw_filtered.set_eeg_reference('average')\n",
    "    # дополнительно можно ICA -> find_bads_eog\n",
    "    \n",
    "    # Нормализация\n",
    "    data = raw_filtered.get_data()  # [n_channels, n_times]\n",
    "    # Z-score по каналам -убрать индивидуальные различия каналов по масштабу, сделать данные сопоставимыми\n",
    "    data_zscored = (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n",
    "    return data_zscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16c80d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datasets with differences in channels\n",
    "# globally used in 2 classes :(\n",
    "needed_channels = [\n",
    "     'C3-P3',\n",
    "     'C4-P4',\n",
    "     'CZ-PZ',\n",
    "     'F3-C3',\n",
    "     'F4-C4',\n",
    "     'F7-T7',\n",
    "     'F8-T8',\n",
    "     'FP1-F3',\n",
    "     'FP1-F7',\n",
    "     'FP2-F4',\n",
    "     'FP2-F8',\n",
    "     'FT10-T8',\n",
    "     'FT9-FT10',\n",
    "     'FZ-CZ',\n",
    "     'P3-O1',\n",
    "     'P4-O2',\n",
    "     'P7-O1',\n",
    "     'P7-T7',\n",
    "     'P8-O2',\n",
    "     'T7-FT9',\n",
    "     'T7-P7',\n",
    "     'T8-P8-0']\n",
    "def get_valid_files(dataset):\n",
    "\n",
    "    res_set = []\n",
    "\n",
    "    for f, label in dataset:\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(f, preload=False, verbose=False)\n",
    "            channels = raw.ch_names\n",
    "            if all(ch in channels for ch in needed_channels):\n",
    "                res_set.append((f, label))\n",
    "        except Exception as e:\n",
    "            print(f\"{f.name}: {e}\")\n",
    "            \n",
    "    return res_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf70232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161\n",
      "454\n",
      "258\n",
      "2131 342 253\n"
     ]
    }
   ],
   "source": [
    "# Get list of files and labels\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import mne\n",
    "from pathlib import Path\n",
    "training_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_set.extend(training_seiz)\n",
    "print(len(training_set))\n",
    "\n",
    "\n",
    "val_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_set.extend(val_seiz)\n",
    "print(len(val_set))\n",
    "\n",
    "\n",
    "test_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_set.extend(test_seiz)\n",
    "print(len(test_set))\n",
    "\n",
    "\n",
    "res_training_set = get_valid_files(training_set)\n",
    "res_val_set = get_valid_files(val_set)\n",
    "res_test_set = get_valid_files(test_set)\n",
    "\n",
    "print(len(res_training_set), len(res_val_set), len(res_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a2a0a",
   "metadata": {},
   "source": [
    "#### HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3565e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head\n",
    "# load backbone\n",
    "backbone = EEGNet(\n",
    "    n_chans=22, \n",
    "    n_outputs=128, \n",
    "    n_times=512,\n",
    "    final_conv_length='auto'\n",
    ")\n",
    "backbone.classify = False\n",
    "backbone.load_state_dict(torch.load(\"backbone_ssl.pt\"))\n",
    "backbone = backbone.cuda()\n",
    "\n",
    "# Head class for classification/regression\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=2):  # out_dim=2 -> 2 pattern first\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "head = Head(in_dim=128, out_dim=2).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(backbone.parameters())+list(head.parameters()), lr=1e-4)\n",
    "# Для создания нескольких независимых друг от друга паттернов (мульти-лейбл) нужен .Sigmoid()\n",
    "# функция ниже как то применяет этот сигмоид у себя внутри\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "734b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with labels\n",
    "class EEGPatternDataset(Dataset):\n",
    "    def __init__(self, file_label_pairs, window_size=512, cut_step=256):\n",
    "        self.samples, self.labels = [], []\n",
    "        for f, y in file_label_pairs:\n",
    "            raw = mne.io.read_raw_edf(f, preload=True)\n",
    "            # select only chanells above (for datasets with different channels)\n",
    "            raw.pick(needed_channels)\n",
    "            # filter raw record, return some numpy obj\n",
    "            data = get_filtered_data(raw)\n",
    "            # превращает обычный список в торч тензор\n",
    "            # y = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
    "                segment = data[:, start:start+window_size]\n",
    "                \n",
    "                self.samples.append(segment.astype(np.float32))\n",
    "                # гарантируем, что y — float32 tensor\n",
    "                label_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "                self.labels.append(label_tensor)  # метка паттерна\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.samples[idx], dtype=torch.float32)\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "273e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head(backbone, head, train_loader, val_loader, epochs=10, lr=1e-3, fine_tune=False):\n",
    "    \n",
    "    \n",
    "    # saving histories\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Заморозить backbone\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(head.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        head.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            # y.float().unsqueeze(1).cuda()\n",
    "            x, y = x.cuda(), y.float().cuda()\n",
    "            with torch.no_grad():\n",
    "                z = backbone(x)\n",
    "            preds = head(z)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Train loss: {total_loss / len(train_loader):.4f}\")\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Валидация\n",
    "        \n",
    "        # Предсказания и метки собираем по всей валидации\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        head.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                # метрики для анализа F1\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                # ошибка\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "                correct += ((preds > 0.5).float() == y).sum().item()\n",
    "                total += y.size(0)\n",
    "                \n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_acc = correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} |\"\n",
    "              f\" Train loss: {avg_train_loss:.4f} | Val loss: {avg_val_loss:.4f} | Val acc: {val_acc:.3f}\")\n",
    "        \n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "        # Бинаризация (0.5 порог)\n",
    "        binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "        precision = precision_score(all_labels, binary_preds)\n",
    "        recall = recall_score(all_labels, binary_preds)\n",
    "        f1 = f1_score(all_labels, binary_preds)\n",
    "\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "        \n",
    "    # ==== 4. Fine-tuning ====\n",
    "    if fine_tune:\n",
    "        print(\"\\nРазмораживаем верхние слои backbone для тонкой настройки...\")\n",
    "        for p in list(backbone.parameters())[-6:]: # total = 12 (4-6 to unfreeze is ok)\n",
    "            p.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(list(backbone.parameters())[-6:] + list(head.parameters()), lr=1e-4)\n",
    "\n",
    "        for epoch in range(3):  # несколько эпох fine-tuning\n",
    "            head.train()\n",
    "            for x, y in tqdm(train_loader, desc=f\"Fine-tune epoch {epoch+1}\"):\n",
    "                # y.float().unsqueeze(1).cuda()\n",
    "                x, y = x.cuda(), y.float().cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                loss = criterion(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f\"Fine-tune epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        print(\"Fine-tuning завершён!\")\n",
    "        \n",
    "\n",
    "    # Сохранение весов \n",
    "    torch.save(head.state_dict(), \"head.pt\")\n",
    "    torch.save(backbone.state_dict(), \"backbone_finetuned.pt\")\n",
    "\n",
    "    # Сохранение истории метрик \n",
    "    history = pd.DataFrame({\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies\n",
    "    })\n",
    "    history.to_csv(\"training_history_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6d0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 5) how to use: after fine-tune validate head -> may need if-else block in code above\n",
    "# 3) Load backbone for 4 epoch (as the best per val-loss) -> >:( something broke >:(\n",
    "# 4) F1, recall, precision -> +, можно ещё ROC-AUC / PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab876964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                      | 0/1567 [00:00<?, ?it/s]/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "Epoch 1/10:   0%|                                      | 0/1567 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# head initialized earlier\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# backbone initialized earlier\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfine_tune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 26\u001b[0m, in \u001b[0;36mtrain_head\u001b[0;34m(backbone, head, train_loader, val_loader, epochs, lr, fine_tune)\u001b[0m\n\u001b[1;32m     24\u001b[0m     z \u001b[38;5;241m=\u001b[39m backbone(x)\n\u001b[1;32m     25\u001b[0m preds \u001b[38;5;241m=\u001b[39m head(z)\n\u001b[0;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/torch/nn/modules/loss.py:706\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eeg_env/lib/python3.10/site-packages/torch/nn/functional.py:3530\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3527\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3528\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# res_training_set initialized earlier\n",
    "# res_val_set initialized earlier\n",
    "train_ds = EEGPatternDataset(res_training_set)\n",
    "val_ds = EEGPatternDataset(res_val_set)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "# head initialized earlier\n",
    "# backbone initialized earlier\n",
    "\n",
    "train_head(backbone, head, train_loader, val_loader, epochs=10, fine_tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e3237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG)",
   "language": "python",
   "name": "eeg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

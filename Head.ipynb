{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e23c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from braindecode.models import EEGNetv4 as EEGNet\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8be00",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd40252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(raw):\n",
    "    \n",
    "    raw_resampled = raw.copy().resample(256)\n",
    "    \n",
    "    # Убираем дрейф и ВЧ-шум → 0.5–45 Гц, мышечные артефакты (EMG), движение кожи\n",
    "    raw_filtered = raw_resampled.copy().filter(l_freq=0.5, h_freq=45)\n",
    "    \n",
    "    # Удаление сетевой наводки (50 Гц)\n",
    "    raw_filtered.notch_filter(freqs=[50])\n",
    "    \n",
    "    # Референцированиe\n",
    "    # Пересчёт в среднее по всем каналам\n",
    "    raw_filtered.set_eeg_reference('average')\n",
    "    # дополнительно можно ICA -> find_bads_eog\n",
    "    \n",
    "    # Нормализация\n",
    "    data = raw_filtered.get_data()  # [n_channels, n_times]\n",
    "    # Z-score по каналам -убрать индивидуальные различия каналов по масштабу, сделать данные сопоставимыми\n",
    "    data_zscored = (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n",
    "    return data_zscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c80d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datasets with differences in channels\n",
    "def get_valid_files(dataset):\n",
    "    needed_channels = [\n",
    "         'C3-P3',\n",
    "         'C4-P4',\n",
    "         'CZ-PZ',\n",
    "         'F3-C3',\n",
    "         'F4-C4',\n",
    "         'F7-T7',\n",
    "         'F8-T8',\n",
    "         'FP1-F3',\n",
    "         'FP1-F7',\n",
    "         'FP2-F4',\n",
    "         'FP2-F8',\n",
    "         'FT10-T8',\n",
    "         'FT9-FT10',\n",
    "         'FZ-CZ',\n",
    "         'P3-O1',\n",
    "         'P4-O2',\n",
    "         'P7-O1',\n",
    "         'P7-T7',\n",
    "         'P8-O2',\n",
    "         'T7-FT9',\n",
    "         'T7-P7',\n",
    "         'T8-P8-0']\n",
    "    res_set = []\n",
    "\n",
    "    for f, label in dataset:\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(f, preload=False, verbose=False)\n",
    "            channels = raw.ch_names\n",
    "            if all(ch in channels for ch in needed_channels):\n",
    "                res_set.append((f, label))\n",
    "        except Exception as e:\n",
    "            print(f\"{f.name}: {e}\")\n",
    "            \n",
    "    return res_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf70232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161\n",
      "454\n",
      "258\n",
      "2131 342 253\n"
     ]
    }
   ],
   "source": [
    "# Get list of files and labels\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import mne\n",
    "from pathlib import Path\n",
    "training_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and not f.startswith(('chb07', 'chb09', 'chb13', 'chb15'\n",
    "                                                                          ,'chb06', 'chb18', 'chb23'))]\n",
    "training_set.extend(training_seiz)\n",
    "print(len(training_set))\n",
    "\n",
    "\n",
    "val_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb07', 'chb09', 'chb13', 'chb15'))]\n",
    "val_set.extend(val_seiz)\n",
    "print(len(val_set))\n",
    "\n",
    "\n",
    "test_set = [(\"patterns/normals/\" + f, [1, 0]) for f in listdir(\"patterns/normals/\") \n",
    "                if isfile(join(\"patterns/normals/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_seiz = [(\"patterns/seizures/\" + f, [0, 1]) for f in listdir(\"patterns/seizures/\") \n",
    "                if isfile(join(\"patterns/seizures/\", f)) and f.startswith(('chb06', 'chb18', 'chb23'))]\n",
    "test_set.extend(test_seiz)\n",
    "print(len(test_set))\n",
    "\n",
    "\n",
    "res_training_set = get_valid_files(training_set)\n",
    "res_val_set = get_valid_files(val_set)\n",
    "res_test_set = get_valid_files(test_set)\n",
    "\n",
    "print(len(res_training_set), len(res_val_set), len(res_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a2a0a",
   "metadata": {},
   "source": [
    "#### HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3565e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<decorator-gen-472>:4: FutureWarning: NOTE: EEGNetv4() is a deprecated class. `EEGNetv4` was renamed to `EEGNet` in v1.12; this alias will be removed in v1.14..\n"
     ]
    }
   ],
   "source": [
    "# Head\n",
    "# load backbone\n",
    "backbone = EEGNet(\n",
    "    n_chans=22, \n",
    "    n_outputs=128, \n",
    "    n_times=512,\n",
    "    final_conv_length='auto'\n",
    ")\n",
    "backbone.classify = False\n",
    "backbone.load_state_dict(torch.load(\"backbone_ssl.pt\"))\n",
    "backbone = backbone.cuda()\n",
    "\n",
    "# Head class for classification/regression\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=1):  # out_dim=1 -> 1 pattern first\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "head = Head(in_dim=128, out_dim=1).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(backbone.parameters())+list(head.parameters()), lr=1e-4)\n",
    "# Для создания нескольких независимых друг от друга паттернов (мульти-лейбл) нужен .Sigmoid()\n",
    "# функция ниже как то применяет этот сигмоид у себя внутри\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with labels\n",
    "class EEGPatternDataset(Dataset):\n",
    "    def __init__(self, file_list, labels, window_size=512, cut_step=256):\n",
    "        self.samples, self.labels = [], []\n",
    "        for f, y in zip(file_list, labels):\n",
    "            raw = mne.io.read_raw_edf(f, preload=True)\n",
    "            # select only chanells above (for datasets with different channels)\n",
    "            raw.pick(needed_channels)\n",
    "            # filter raw record, return some numpy obj\n",
    "            data = get_filtered_data(raw)\n",
    "            \n",
    "            for start in range(0, data.shape[1]-window_size, cut_step):\n",
    "                segment = data[:, start:start+window_size]\n",
    "                \n",
    "                self.samples.append(segment.astype(np.float32))\n",
    "                self.labels.append(y)  # метка паттерна\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "273e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head(backbone, head, train_loader, val_loader, epochs=10, lr=1e-3, fine_tune=False):\n",
    "    \n",
    "    \n",
    "    # saving histories\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Заморозить backbone\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(head.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        head.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x, y = x.cuda(), y.float().unsqueeze(1).cuda()\n",
    "            with torch.no_grad():\n",
    "                z = backbone(x)\n",
    "            preds = head(z)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Train loss: {total_loss / len(train_loader):.4f}\")\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Валидация\n",
    "        head.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "                correct += ((preds > 0.5).float() == y.unsqueeze(1)).sum().item()\n",
    "                total += y.size(0)\n",
    "                \n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_acc = correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} |\"\n",
    "              f\" Train loss: {avg_train_loss:.4f} | Val loss: {avg_val_loss:.4f} | Val acc: {val_acc:.3f}\")\n",
    "\n",
    "        \n",
    "    # ==== 4. Fine-tuning ====\n",
    "    if fine_tune:\n",
    "        print(\"\\nРазмораживаем верхние слои backbone для тонкой настройки...\")\n",
    "        for p in list(backbone.parameters())[-6:]: # total = 12 (4-6 to unfreeze is ok)\n",
    "            p.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(list(backbone.parameters())[-6:] + list(head.parameters()), lr=1e-4)\n",
    "\n",
    "        for epoch in range(3):  # несколько эпох fine-tuning\n",
    "            head.train()\n",
    "            for x, y in tqdm(train_loader, desc=f\"Fine-tune epoch {epoch+1}\"):\n",
    "                x, y = x.cuda(), y.float().unsqueeze(1).cuda()\n",
    "                z = backbone(x)\n",
    "                preds = head(z)\n",
    "                loss = criterion(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f\"Fine-tune epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        print(\"Fine-tuning завершён!\")\n",
    "        \n",
    "\n",
    "    # Сохранение весов \n",
    "    torch.save(head.state_dict(), \"head.pt\")\n",
    "    torch.save(backbone.state_dict(), \"backbone_finetuned.pt\")\n",
    "\n",
    "    # Сохранение истории метрик \n",
    "    history = pd.DataFrame({\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies\n",
    "    })\n",
    "    history.to_csv(\"training_history_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6d0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 5) how to use: after fine-tune validate head -> may need if-else block in code above\n",
    "# 3) Load backbone for 4 epoch (as the best per val-loss) -> >:( something broke >:(\n",
    "# 4) F1, recall, precision\n",
    "# 5) how to use: launch head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab876964",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EEGPatternDataset([\"pattern1.edf\", \"pattern2.edf\"], labels=[[1,0,0],[0,1,0]])\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e3237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG)",
   "language": "python",
   "name": "eeg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
